{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1b0d5b5-0ed8-46f2-bd0b-7cedee9933f6",
   "metadata": {},
   "source": [
    " # TD 2: Focus on interpretability\n",
    " In this practical class, we will implement a method to investigate the importance of the features inputed to\n",
    " the classifier, in order to interpret how the classifier has learnt to distinguish healthy controls from depression\n",
    " patients using voice only.\n",
    " In a first approach, we will only focus on the eGeMAPS features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f00052a-7457-401c-9b07-88458da7d40c",
   "metadata": {},
   "source": [
    "## 1 Linear models (*)\n",
    "In this section (and in this section only), we will use a SVM with a linear kernel.\n",
    "### 1.1 Read speech\n",
    "**Task n°1. Implement and evaluate this classifier on the read subcorpus of the Android corpus.**\n",
    "Since the classifier is linear, it is possible to extract the coefficients of the classifier for each feature.\\\n",
    "**Task n°2. Extract the coefficient of the linear SVM for each fold.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa1361a-5c94-4a4a-9261-2b51622a5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# --- 1. FONCTION DE CHARGEMENT DES DONNÉES ---\n",
    "def load_and_preprocess_data(base_path=\"/Users/klockjoely/Downloads/feautres_android_means/reading_means\"):\n",
    "    \"\"\"Charge et prépare les données HC et PT du sous-corpus 'reading means'.\"\"\"\n",
    "    data_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # 1. Charger les données HC (Sains) -> Étiquette 0\n",
    "    hc_path = os.path.join(base_path, 'HC')\n",
    "    # Utilisez try-except pour gérer les erreurs si le chemin n'est pas trouvé\n",
    "    try:\n",
    "        for filename in os.listdir(hc_path):\n",
    "            if filename.endswith('.csv'):\n",
    "                filepath = os.path.join(hc_path, filename)\n",
    "                df = pd.read_csv(filepath)\n",
    "                data_list.append(df)\n",
    "                labels_list.append(0) # Étiquette 0 pour HC\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur: Le chemin HC n'a pas été trouvé: {hc_path}\")\n",
    "        return np.array([]), np.array([]), [] # Retourne des tableaux vides en cas d'erreur\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite lors du chargement des données HC : {e}\")\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    # 2. Charger les données PT (Malades) -> Étiquette 1\n",
    "    pt_path = os.path.join(base_path, 'PT')\n",
    "    try:\n",
    "        for filename in os.listdir(pt_path):\n",
    "            if filename.endswith('.csv'):\n",
    "                filepath = os.path.join(pt_path, filename)\n",
    "                df = pd.read_csv(filepath)\n",
    "                data_list.append(df)\n",
    "                labels_list.append(1) # Étiquette 1 pour PT\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur: Le chemin PT n'a pas été trouvé: {pt_path}\")\n",
    "        return np.array([]), np.array([]), []\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur s'est produite lors du chargement des données PT : {e}\")\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    # Vérifiez si des données ont été chargées\n",
    "    if not data_list:\n",
    "        print(\"Aucun fichier CSV trouvé ou les chemins d'accès sont incorrects.\")\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    # --- Option 1 : Chaque ligne est un exemple indépendant ---\n",
    "    # Concaténation des DataFrames\n",
    "    X_full = pd.concat(data_list, ignore_index=True)\n",
    "    \n",
    "    # Création du vecteur d'étiquettes\n",
    "    y_full = np.concatenate([[label] * len(data) for data, label in zip(data_list, labels_list)])\n",
    "\n",
    "    # 4. Séparer Features (X) et Labels (y) et nettoyer les colonnes\n",
    "    columns_to_drop = ['file', 'start', 'end']\n",
    "    \n",
    "    # Assurez-vous que les colonnes existent avant de les supprimer\n",
    "    cols_to_drop_present = [col for col in columns_to_drop if col in X_full.columns]\n",
    "    X = X_full.drop(cols_to_drop_present, axis=1)\n",
    "\n",
    "    # Sauvegarde des noms de features\n",
    "    feature_names = X.columns.tolist()\n",
    "    \n",
    "    # Conversion en numpy array\n",
    "    X = X.to_numpy()\n",
    "    \n",
    "    return X, y_full, feature_names\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# --- 2. FONCTION DE CLASSIFICATION ET ÉVALUATION ---\n",
    "def test_k_folds_android():\n",
    "    # 1. Chargement des données \n",
    "    X, y, feature_names = load_and_preprocess_data()\n",
    "    \n",
    "    # Vérification du chargement\n",
    "    if X.size == 0 or y.size == 0:\n",
    "        print(\"\\nArrêt du script : Données de chargement non valides.\")\n",
    "        return\n",
    "\n",
    "    # 2. Initialisation du classifieur\n",
    "    # SVC avec un noyau linéaire est un classifieur linéaire.\n",
    "    clf = SVC(kernel='linear', C=1, random_state=42)\n",
    "    \n",
    "    # 3. Validation Croisée (cv=5)\n",
    "    # return_estimator=True est essentiel pour récupérer les modèles entraînés\n",
    "    cv_results = cross_validate(\n",
    "        clf, X, y, \n",
    "        cv=5, \n",
    "        scoring='accuracy', \n",
    "        return_estimator=True\n",
    "    )\n",
    "    \n",
    "    # 4. Évaluation\n",
    "    mean_accuracy = cv_results[\"test_score\"].mean()\n",
    "    print(\"\\n--- ÉVALUATION PAR VALIDATION CROISÉE ---\")\n",
    "    print(f\"Précision moyenne (5-Fold CV): {mean_accuracy:.4f}\")\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # 5. Extraction et Analyse des Coefficients (MIS À JOUR)\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- ANALYSE DES COEFFICIENTS DU CLASSIFIEUR PAR PLI ---\")\n",
    "    \n",
    "    # Récupérer les 5 classifieurs entraînés\n",
    "    estimators = cv_results[\"estimator\"]\n",
    "    \n",
    "    # Liste pour stocker les DataFrames de coefficients par pli\n",
    "    fold_coeffs_dfs = []\n",
    "    all_coeffs = []\n",
    "\n",
    "    # Itérer sur chaque estimateur entraîné\n",
    "    for i, estimator in enumerate(estimators):\n",
    "        fold_coeffs = estimator.coef_.flatten()\n",
    "        all_coeffs.append(fold_coeffs)\n",
    "        \n",
    "        # Créer un DataFrame pour ce pli\n",
    "        fold_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            f'Fold_{i+1}_Coefficient': fold_coeffs \n",
    "        })\n",
    "        fold_coeffs_dfs.append(fold_df.set_index('Feature'))\n",
    "        \n",
    "        # Affichage du top/bottom 3 pour le pli actuel\n",
    "        print(f\"\\nCoefficients du Pli {i+1} (Top/Bottom 3) :\")\n",
    "        print(fold_df.sort_values(by=f'Fold_{i+1}_Coefficient', ascending=False).head(3))\n",
    "        print(fold_df.sort_values(by=f'Fold_{i+1}_Coefficient', ascending=False).tail(3))\n",
    "        \n",
    "\n",
    "    # Concaténer tous les résultats des plis dans un seul DataFrame\n",
    "    # Note: L'utilisation de pd.concat avec axis=1 nécessite que l'index (Feature) soit défini\n",
    "    all_folds_combined_df = pd.concat(fold_coeffs_dfs, axis=1).reset_index()\n",
    "    \n",
    "    # Calculer la moyenne des coefficients sur les 5 folds\n",
    "    mean_coeffs = np.mean(all_coeffs, axis=0)\n",
    "    \n",
    "    # Ajouter la moyenne au DataFrame combiné pour une vue complète\n",
    "    all_folds_combined_df['Mean_Coefficient'] = mean_coeffs\n",
    "\n",
    "    # Créer un DataFrame pour afficher le Top 5 de la MOYENNE (comme dans votre sortie originale)\n",
    "    mean_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Mean_Coefficient': mean_coeffs\n",
    "    }).sort_values(by='Mean_Coefficient', ascending=False)\n",
    "    \n",
    "    # Affichage des résultats basés sur la moyenne\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"--- RÉSULTATS AGRÉGÉS (MOYENNE) ---\")\n",
    "    print(mean_df.head(5).to_string(index=False))\n",
    "    \n",
    "    print(\"\\nTop 5 des features avec les coefficients négatifs les plus faibles (Favorise la classe 0 - HC):\")\n",
    "    print(mean_df.tail(5).to_string(index=False))\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\n--- APERÇU DU TABLEAU COMPLET (Coefficients par pli et Moyenne) ---\")\n",
    "    # Afficher les 10 premières lignes du DataFrame complet\n",
    "    cols_order = ['Feature', 'Mean_Coefficient'] + [col for col in all_folds_combined_df.columns if col.startswith('Fold_')]\n",
    "    print(all_folds_combined_df[cols_order].head(10).to_string(index=False))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Lancez la fonction d'évaluation\n",
    "    test_k_folds_android()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b3c18-a661-4548-b049-8ab6f5107202",
   "metadata": {},
   "source": [
    "**Task n°3. Plot the average relative contribution (%) of each feature with standard-deviation (e.g. using a box plot).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29c9d3-56a1-4de0-81dd-97e79539612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "try:\n",
    "    _ = all_folds_combined_df \n",
    "    print(\"Utilisation du DataFrame 'all_folds_combined_df' existant.\")\n",
    "except NameError:\n",
    "    print(\"Le DataFrame 'all_folds_combined_df' n'est pas défini. Utilisation de données simulées pour le graphique.\")\n",
    "\n",
    "# Les colonnes de coefficients pour le calcul (identifiez-les dynamiquement si possible)\n",
    "# On suppose que les colonnes de coefficients commencent par 'Fold_' et se terminent par '_Coefficient'\n",
    "coeff_cols = [col for col in all_folds_combined_df.columns if col.startswith('Fold_') and col.endswith('_Coefficient')]\n",
    "\n",
    "# S'assurer que 'Feature' est la première colonne pour faciliter le traitement\n",
    "if 'Feature' in all_folds_combined_df.columns:\n",
    "    df_plot_data = all_folds_combined_df[['Feature'] + coeff_cols].copy()\n",
    "else:\n",
    "    # Si 'Feature' est l'index, le réinitialiser\n",
    "    df_plot_data = all_folds_combined_df[coeff_cols].copy()\n",
    "    df_plot_data = df_plot_data.reset_index().rename(columns={'index': 'Feature'})\n",
    "\n",
    "\n",
    "# Calculer la contribution relative (%) pour chaque pli\n",
    "df_rel_contrib = df_plot_data[['Feature']].copy()\n",
    "\n",
    "for col in coeff_cols:\n",
    "    # Calculer la valeur absolue du coefficient pour la colonne actuelle\n",
    "    abs_coeffs = df_plot_data[col].abs()\n",
    "    \n",
    "    # Calculer la somme totale des contributions absolues pour ce pli.\n",
    "    # Ajouter une petite constante pour éviter la division par zéro si la somme est 0 (très rare)\n",
    "    sum_abs_coeffs = abs_coeffs.sum() + 1e-9 # Ajout d'une petite valeur\n",
    "    \n",
    "    # Calculer la contribution relative en pourcentage\n",
    "    df_rel_contrib[f'Relative_Contribution_{col.split(\"_\")[1]}'] = (abs_coeffs / sum_abs_coeffs) * 100\n",
    "\n",
    "# Mettre les données au format long pour le box plot (seaborn)\n",
    "# On garde 'Feature' et on met les colonnes de contribution en lignes\n",
    "df_long = df_rel_contrib.melt(\n",
    "    id_vars='Feature', \n",
    "    value_vars=[col for col in df_rel_contrib.columns if col.startswith('Relative_Contribution')], \n",
    "    var_name='Fold', \n",
    "    value_name='Contribution (%)'\n",
    ")\n",
    "\n",
    "# Calculer la moyenne de la contribution pour trier les features dans le graphique\n",
    "mean_contributions = df_long.groupby('Feature')['Contribution (%)'].mean().sort_values(ascending=False)\n",
    "sorted_features = mean_contributions.index\n",
    "\n",
    "# --- Configuration et Génération du Box Plot ---\n",
    "plt.figure(figsize=(12, max(6, len(sorted_features) * 0.4))) # Taille dynamique du graphique\n",
    "sns.boxplot(\n",
    "    x='Contribution (%)', \n",
    "    y='Feature', \n",
    "    data=df_long, \n",
    "    order=sorted_features, \n",
    "    palette=\"viridis\" # Ou une autre palette de couleurs comme \"coolwarm\", \"plasma\"\n",
    ")\n",
    "plt.title('Contribution Relative Moyenne des Caractéristiques (SVM Linéaire) avec Écart-type', fontsize=14)\n",
    "plt.xlabel('Contribution Relative (%)', fontsize=12)\n",
    "plt.ylabel('Caractéristique', fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6) # Ajoute une grille horizontale\n",
    "plt.tight_layout() # Ajuste automatiquement les paramètres de la figure pour les marges\n",
    "plt.show() # Affiche le graphique\n",
    "\n",
    "# Optionnel : Enregistrer le graphique dans un fichier\n",
    "# plt.savefig('relative_contribution_boxplot.png', dpi=300) \n",
    "# print(\"Le graphique a été enregistré sous 'relative_contribution_boxplot.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a4c794-9a5f-4853-a386-5d725153cb0c",
   "metadata": {},
   "source": [
    "**Q1. What are the most important features?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ae89a-9b21-4a4a-afcc-72c50205b1c1",
   "metadata": {},
   "source": [
    "**Q2. Write a paragraph describing the impact of depression on read speech according to the classifier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783f41b-29e4-4195-864e-df57e05a1769",
   "metadata": {},
   "source": [
    "### 1.2 Spontaneous speech\n",
    "**Task n°4. Do the same for spontaneous speech.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f03f9-c636-49ee-87bc-fa2b40e1a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. FONCTION DE CHARGEMENT DES DONNÉES (CORRIGÉE) ---\n",
    "def load_and_preprocess_data(base_path=\"/Users/klockjoely/Downloads/feautres_android_means/spontaneous_means\"):\n",
    "    \"\"\"\n",
    "    Charge et prépare les données du sous-corpus 'spontaneous' \n",
    "    à partir du fichier CSV agrégé en utilisant la colonne 'directory' pour les étiquettes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTE: Assurez-vous que le fichier 'directory_means.csv' est dans le dossier spécifié par base_path\n",
    "    csv_file_path = os.path.join(base_path, '/Users/klockjoely/Downloads/directory_means.csv')\n",
    "    \n",
    "    try:\n",
    "        # Tente de lire le fichier\n",
    "        X_full = pd.read_csv(csv_file_path)\n",
    "    except FileNotFoundError:\n",
    "        # Si le fichier n'est pas trouvé\n",
    "        print(f\"Erreur: Le fichier {csv_file_path} n'a pas été trouvé. Vérifiez le chemin.\")\n",
    "        return np.array([]), np.array([]), []\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur de lecture du fichier CSV : {e}\")\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    # 1. CRÉATION DES ÉTIQUETTES à partir de la colonne 'directory'\n",
    "    # 0 = Control (HC), 1 = Patient (PT)\n",
    "    try:\n",
    "        X_full['label'] = X_full['directory'].str[3].apply(lambda x: 0 if x == 'C' else 1).astype(int)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction des étiquettes à partir de la colonne 'directory' : {e}\")\n",
    "        return np.array([]), np.array([]), []\n",
    "\n",
    "    # 2. Séparer les étiquettes\n",
    "    y_full = X_full['label'].to_numpy()\n",
    "\n",
    "    # 3. Nettoyer les colonnes non-features\n",
    "    columns_to_drop = ['directory', 'label']\n",
    "    \n",
    "    # Vérification et suppression des colonnes\n",
    "    cols_to_drop_present = [col for col in columns_to_drop if col in X_full.columns]\n",
    "    X = X_full.drop(cols_to_drop_present, axis=1)\n",
    "\n",
    "    # Sauvegarde des noms de features et conversion\n",
    "    feature_names = X.columns.tolist()\n",
    "    X = X.to_numpy()\n",
    "    \n",
    "    return X, y_full, feature_names\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# --- 2. FONCTION DE CLASSIFICATION ET ÉVALUATION ---\n",
    "def test_k_folds_android(plot=True):\n",
    "    # 1. Chargement des données \n",
    "    X, y, feature_names = load_and_preprocess_data()\n",
    "    \n",
    "    if X.size == 0 or y.size == 0:\n",
    "        print(\"\\nArrêt du script : Données de chargement non valides.\")\n",
    "        return\n",
    "\n",
    "    # 2. Initialisation du classifieur\n",
    "    clf = SVC(kernel='linear', C=1, random_state=42)\n",
    "    \n",
    "    # 3. Validation Croisée (cv=5)\n",
    "    cv_results = cross_validate(\n",
    "        clf, X, y, \n",
    "        cv=5, \n",
    "        scoring='accuracy', \n",
    "        return_estimator=True\n",
    "    )\n",
    "    \n",
    "    # 4. Évaluation\n",
    "    mean_accuracy = cv_results[\"test_score\"].mean()\n",
    "    print(\"\\n--- ÉVALUATION PAR VALIDATION CROISÉE (SPONTANEOUS) ---\")\n",
    "    print(f\"Précision moyenne (5-Fold CV): {mean_accuracy:.4f}\")\n",
    "    \n",
    "    # 5. Extraction des Coefficients (OUI, C'EST LE BLOC DE CODE QUE VOUS VOULEZ GARDER POUR L'ANALYSE)\n",
    "    print(\"\\n--- ANALYSE DES COEFFICIENTS DU CLASSIFIEUR PAR PLI ---\")\n",
    "    \n",
    "    estimators = cv_results[\"estimator\"]\n",
    "    fold_coeffs_dfs = []\n",
    "    all_coeffs = []\n",
    "\n",
    "    for i, estimator in enumerate(estimators):\n",
    "        fold_coeffs = estimator.coef_.flatten()\n",
    "        all_coeffs.append(fold_coeffs)\n",
    "        fold_df = pd.DataFrame({'Feature': feature_names, f'Fold_{i+1}_Coefficient': fold_coeffs })\n",
    "        fold_coeffs_dfs.append(fold_df.set_index('Feature'))\n",
    "        print(f\"\\nCoefficients du Pli {i+1} (Top/Bottom 3) :\")\n",
    "        print(fold_df.sort_values(by=f'Fold_{i+1}_Coefficient', ascending=False).head(3).to_string(index=False))\n",
    "        print(fold_df.sort_values(by=f'Fold_{i+1}_Coefficient', ascending=False).tail(3).to_string(index=False))\n",
    "        \n",
    "    all_folds_combined_df = pd.concat(fold_coeffs_dfs, axis=1).reset_index()\n",
    "    mean_coeffs = np.mean(all_coeffs, axis=0)\n",
    "    all_folds_combined_df['Mean_Coefficient'] = mean_coeffs\n",
    "    mean_df = pd.DataFrame({'Feature': feature_names, 'Mean_Coefficient': mean_coeffs}).sort_values(by='Mean_Coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"--- RÉSULTATS AGRÉGÉS (MOYENNE) ---\")\n",
    "    print(\"\\nTop 5 des features positives (Favorise la classe 1 - PT):\")\n",
    "    print(mean_df.head(5).to_string(index=False))\n",
    "    print(\"\\nTop 5 des features négatives (Favorise la classe 0 - HC):\")\n",
    "    print(mean_df.tail(5).to_string(index=False))\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # 6. Tracé du Box Plot de la Contribution Relative\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    if plot:\n",
    "        plot_relative_contribution(all_folds_combined_df)\n",
    "        \n",
    "    return all_folds_combined_df \n",
    "\n",
    "# --- 3. FONCTION DE TRACÉ DU BOX PLOT ---\n",
    "def plot_relative_contribution(df_combined):\n",
    "    \"\"\"Génère le box plot de la contribution relative des coefficients par pli.\"\"\"\n",
    "    \n",
    "    # Les colonnes de coefficients (Fold)\n",
    "    coeff_cols = [col for col in df_combined.columns if col.startswith('Fold_') and col.endswith('_Coefficient')]\n",
    "\n",
    "    df_plot_data = df_combined[['Feature'] + coeff_cols].copy()\n",
    "    df_rel_contrib = df_plot_data[['Feature']].copy()\n",
    "\n",
    "    for col in coeff_cols:\n",
    "        abs_coeffs = df_plot_data[col].abs()\n",
    "        sum_abs_coeffs = abs_coeffs.sum() + 1e-9 \n",
    "        df_rel_contrib[f'Relative_Contribution_{col.split(\"_\")[1]}'] = (abs_coeffs / sum_abs_coeffs) * 100\n",
    "\n",
    "    df_long = df_rel_contrib.melt(\n",
    "        id_vars='Feature', \n",
    "        value_vars=[col for col in df_rel_contrib.columns if col.startswith('Relative_Contribution')], \n",
    "        var_name='Fold', \n",
    "        value_name='Contribution (%)'\n",
    "    )\n",
    "\n",
    "    mean_contributions = df_long.groupby('Feature')['Contribution (%)'].mean().sort_values(ascending=False)\n",
    "    sorted_features = mean_contributions.index\n",
    "\n",
    "    # --- Génération du Box Plot ---\n",
    "    plt.figure(figsize=(12, max(6, len(sorted_features) * 0.4)))\n",
    "    sns.boxplot(\n",
    "        x='Contribution (%)', \n",
    "        y='Feature', \n",
    "        data=df_long, \n",
    "        order=sorted_features, \n",
    "        palette=\"coolwarm\"\n",
    "    )\n",
    "    plt.title('Contribution Relative Moyenne des Caractéristiques (SPONTANEOUS)', fontsize=14)\n",
    "    plt.xlabel('Contribution Relative (%)', fontsize=12)\n",
    "    plt.ylabel('Caractéristique', fontsize=12)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # LIGNE À RETIRER/COMMENTER POUR ÉVITER L'OSError :\n",
    "    # plt.savefig('relative_contribution_spontaneous_boxplot.png') \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Lancez l'analyse pour le sous-corpus spontané\n",
    "    test_k_folds_android()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f80036-4393-4ab2-8053-52230fd08a2b",
   "metadata": {},
   "source": [
    "**Q3. Are the features that are important for reading the same as those for spontaneous speech?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
