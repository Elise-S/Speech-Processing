{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d932699",
   "metadata": {},
   "source": [
    "# Speech Processing - TD1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1ee58",
   "metadata": {},
   "source": [
    "## Part 1: Qualitative analysis of audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972416d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Question 1: In your opinion, why do we use this dataset?**\n",
    "\n",
    "A1 - This dataset is one of the rare health and speech dataset available that presents those characteristics:\n",
    "* All labels came from the diagnosis of clinicians;\n",
    "* All parameters of speakers are equilibrate: age, gender (that reflect reality), control and depressed groups, education level;\n",
    "* It has been recorded in real-life setting conditions in hospital, with laptop microphones;\n",
    "* The language used in this dataset was Italian, a language pretty under-resourced;\n",
    "* It can be easily re-used to perform classification task on speech features (like the authors did for depression in their article)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707d98cf",
   "metadata": {},
   "source": [
    "**Task 3: Plot a spectrogram (to see quality of audio signal)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc813e53",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# installations\n",
    "!pip install -U praat-parselmouth\n",
    "import parselmouth\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b25d89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Spectrogram\n",
    "def draw_spectrogram(spectrogram, dynamic_range=70):\n",
    "    X, Y = spectrogram.x_grid(), spectrogram.y_grid()\n",
    "    sg_db = 10 * np.log10(spectrogram.values)\n",
    "    plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap='afmhot')\n",
    "    plt.ylim([spectrogram.ymin, spectrogram.ymax])\n",
    "    plt.xlabel(\"time [s]\")\n",
    "    plt.ylabel(\"frequency [Hz]\")\n",
    "\n",
    "def draw_intensity(intensity, color='w', linecolor='blue'):\n",
    "    plt.plot(intensity.xs(), intensity.values.T, linewidth=3, color=color)\n",
    "    plt.plot(intensity.xs(), intensity.values.T, linewidth=1, color=linecolor)\n",
    "    plt.grid(False)\n",
    "    plt.ylim(0)\n",
    "    plt.ylabel(\"intensity [dB]\")\n",
    "\n",
    "# List of audio file paths\n",
    "audio_files = [\n",
    "    r\"C:\\Users\\Elise\\Desktop\\COURS\\S9 (papapapaaaaa)\\Speech Processing\\Androids-Corpus\\Androids-Corpus\\Interview-Task\\audio_clip\\01_CF56_1\\01_CF56_1_6.wav\",\n",
    "    r\"C:\\Users\\Elise\\Desktop\\COURS\\S9 (papapapaaaaa)\\Speech Processing\\Androids-Corpus\\Androids-Corpus\\Interview-Task\\audio_clip\\25_CF59_3\\25_CF59_3_2.wav\",\n",
    "    r\"C:\\Users\\Elise\\Desktop\\COURS\\S9 (papapapaaaaa)\\Speech Processing\\Androids-Corpus\\Androids-Corpus\\Reading-Task\\audio\\HC\\54_CM48_2.wav\",\n",
    "    r\"C:\\Users\\Elise\\Desktop\\COURS\\S9 (papapapaaaaa)\\Speech Processing\\Androids-Corpus\\Androids-Corpus\\Reading-Task\\audio\\PT\\09_PM60_2.wav\"\n",
    "]\n",
    "\n",
    "# Custom titles for each audio file\n",
    "audio_titles = [\n",
    "    \"Interview (clip audio) - HC\",\n",
    "    \"Interview (clip audio) - PT\",\n",
    "    \"Reading - HC\",\n",
    "    \"Reading - PT\"\n",
    "]\n",
    "\n",
    "# Use seaborn's default style\n",
    "sns.set()\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Create a figure with 2 rows and 4 columns (spectrogram + zoomed intensity for each file)\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "for idx, audio_file in enumerate(audio_files):\n",
    "    try:\n",
    "        # Load sound file\n",
    "        snd = parselmouth.Sound(audio_file)\n",
    "        intensity = snd.to_intensity()\n",
    "        spectrogram = snd.to_spectrogram()\n",
    "        \n",
    "        # Spectrogram plot (top row)\n",
    "        ax1 = plt.subplot(2, 4, idx + 1)\n",
    "        draw_spectrogram(spectrogram)\n",
    "        ax2 = ax1.twinx()\n",
    "        draw_intensity(intensity)\n",
    "        plt.xlim([snd.xmin, snd.xmax])\n",
    "        plt.title(audio_titles[idx])\n",
    "        \n",
    "        # Zoomed intensity plot (bottom row)\n",
    "        ax3 = plt.subplot(2, 4, idx + 5)\n",
    "        plt.plot(intensity.xs(), intensity.values.T, linewidth=2, color='blue')\n",
    "        plt.xlabel(\"time [s]\")\n",
    "        plt.ylabel(\"intensity [dB]\")\n",
    "        plt.title(f\"{audio_titles[idx]} - Intensity\")\n",
    "        plt.xlim([snd.xmin, snd.xmax])\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # time window:\n",
    "        plt.xlim([0, 2])  # set at 2 seconds\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {audio_file}: {e}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7b8195",
   "metadata": {},
   "source": [
    "**Question 2: What are the characteristics of these audio files? (sampling rate, bitrate, duration, approximative Signal-to-Noise ratio?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db149ff2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Q2:\n",
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param a: the speech waveform\n",
    "    :param axis: the axis to compute the mean\n",
    "    :param ddof: \n",
    "    :return: the signal-to-noise\n",
    "    \"\"\"\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "\n",
    "def question_2():\n",
    "    \"\"\"\n",
    "    Answer to question: retrieve all requiered informations from hc, pt and all files then compute avg, std, min, max of\n",
    "    these variables. \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Task 3\n",
    "    root_hc = r'C:\\Users\\Cam\\PycharmProjects\\td_speech_processing\\Androids-Corpus\\Interview-Task\\audio\\HC'\n",
    "    root_pt = r'C:\\Users\\Cam\\PycharmProjects\\td_speech_processing\\Androids-Corpus\\Interview-Task\\audio\\PT'\n",
    "\n",
    "    filenames_hc = [f'{root_hc}/{f}' for f in listdir(root_hc) if isfile(join(root_hc, f))]\n",
    "    filenames_pt = [f'{root_pt}/{f}' for f in listdir(root_pt) if isfile(join(root_pt, f))]\n",
    "\n",
    "    all_files = filenames_hc + filenames_pt\n",
    "\n",
    "    durations = []\n",
    "    snrs = []\n",
    "    sample_rates = []\n",
    "    bitrates = []\n",
    "\n",
    "    print(\"All filenames_hc\")\n",
    "    for file in filenames_hc:\n",
    "        # Load audio\n",
    "        SPEECH_WAVEFORM, SAMPLE_RATE = torchaudio.load(file)\n",
    "        sample_rates.append(SAMPLE_RATE)\n",
    "        snr = signaltonoise(SPEECH_WAVEFORM.numpy()[0])\n",
    "        snrs.append(snr)\n",
    "        duration = SPEECH_WAVEFORM.shape[1] / SAMPLE_RATE\n",
    "        metadata = torchaudio.info(file)\n",
    "        bitrate = metadata.sample_rate * metadata.bits_per_sample / 1000\n",
    "        bitrates.append(bitrate)\n",
    "        durations.append(duration)\n",
    "\n",
    "    print(f\"Sample rate: {set(sample_rates)}\\n\"\n",
    "          f\"Bitrate: {set(bitrates)}\\n\"\n",
    "          f\"Mean duration: {round(np.mean(durations), 3)}'s\\n\"\n",
    "          f\"Std duration: {round(np.std(durations), 3)}'s\\n\"\n",
    "          f\"Min duration: {round(np.min(durations), 3)}'s\\n\"\n",
    "          f\"Max duration: {round(np.max(durations), 3)}'s\\n\"\n",
    "          f\"Mean snr: {round(np.mean(snrs), 7)}'s\\n\"\n",
    "          f\"Std snr: {round(np.std(snrs), 7)}'s\\n\"\n",
    "          f\"Min snr: {round(np.min(snrs), 7)}'s\\n\"\n",
    "          f\"Max snr: {round(np.max(snrs), 7)}'s\\n\"\n",
    "          )\n",
    "\n",
    "\n",
    "    durations = []\n",
    "    snrs = []\n",
    "    sample_rates = []\n",
    "    bitrates = []\n",
    "    print(\"All filenames_pt\")\n",
    "    for file in filenames_pt:\n",
    "        # Load audio\n",
    "        SPEECH_WAVEFORM, SAMPLE_RATE = torchaudio.load(file)\n",
    "        sample_rates.append(SAMPLE_RATE)\n",
    "        snr = signaltonoise(SPEECH_WAVEFORM.numpy()[0])\n",
    "        snrs.append(snr)\n",
    "        duration = SPEECH_WAVEFORM.shape[1] / SAMPLE_RATE\n",
    "        metadata = torchaudio.info(file)\n",
    "        bitrate = metadata.sample_rate * metadata.bits_per_sample / 1000\n",
    "        bitrates.append(bitrate)\n",
    "        durations.append(duration)\n",
    "\n",
    "    print(f\"Sample rate: {set(sample_rates)}\\n\"\n",
    "          f\"Bitrate: {set(bitrates)}\\n\"\n",
    "          f\"Mean duration: {round(np.mean(durations), 3)}'s\\n\"\n",
    "          f\"Std duration: {round(np.std(durations), 3)}'s\\n\"\n",
    "          f\"Min duration: {round(np.min(durations), 3)}'s\\n\"\n",
    "          f\"Max duration: {round(np.max(durations), 3)}'s\\n\"\n",
    "          f\"Mean snr: {round(np.mean(snrs), 7)}'s\\n\"\n",
    "          f\"Std snr: {round(np.std(snrs), 7)}'s\\n\"\n",
    "          f\"Min snr: {round(np.min(snrs), 7)}'s\\n\"\n",
    "          f\"Max snr: {round(np.max(snrs), 7)}'s\\n\")\n",
    "\n",
    "    durations = []\n",
    "    snrs = []\n",
    "    sample_rates = []\n",
    "    bitrates = []\n",
    "    print(\"All files\")\n",
    "    for file in all_files:\n",
    "        # Load audio\n",
    "        SPEECH_WAVEFORM, SAMPLE_RATE = torchaudio.load(file)\n",
    "        sample_rates.append(SAMPLE_RATE)\n",
    "        snr = signaltonoise(SPEECH_WAVEFORM.numpy()[0])\n",
    "        snrs.append(snr)\n",
    "        duration = SPEECH_WAVEFORM.shape[1] / SAMPLE_RATE\n",
    "        metadata = torchaudio.info(file)\n",
    "        bitrate = metadata.sample_rate * metadata.bits_per_sample / 1000\n",
    "        bitrates.append(bitrate)\n",
    "        durations.append(duration)\n",
    "\n",
    "    print(f\"Sample rate: {set(sample_rates)}\\n\"\n",
    "          f\"Bitrate: {set(bitrates)}\\n\"\n",
    "          f\"Mean duration: {round(np.mean(durations), 3)}'s\\n\"\n",
    "          f\"Std duration: {round(np.std(durations), 3)}'s\\n\"\n",
    "          f\"Min duration: {round(np.min(durations), 3)}'s\\n\"\n",
    "          f\"Max duration: {round(np.max(durations), 3)}'s\\n\"\n",
    "          f\"Mean snr: {round(np.mean(snrs), 7)}'s\\n\"\n",
    "          f\"Std snr: {round(np.std(snrs), 7)}'s\\n\"\n",
    "          f\"Min snr: {round(np.min(snrs), 7)}'s\\n\"\n",
    "          f\"Max snr: {round(np.max(snrs), 7)}'s\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae4be4",
   "metadata": {},
   "source": [
    "**Question 3: What is the number of sample per speaker?** \\\n",
    "A: Given that there is normally only one sample in the reading and interview, the normal total number should be two samples per speaker. However, some speakers did not pass certain tests, so some speakers have only one sample or no sample at all. It is also worth noting that in the audio clip folder there are more samples per speaker, but we did not count them in the total because these samples are extracts from the sample already existing in the interview (only the participants' answers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32e108",
   "metadata": {},
   "source": [
    "**Question 4: Are the differences between reading and spontaneous speech? Make a comparative table between the two types of speech.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453bd17",
   "metadata": {},
   "source": [
    "| features     | Reading     | Spontaneous   |\n",
    "|--------------|-------------|---------------|\n",
    "| types of speech   | controlled | spontaneous (natural) |\n",
    "|   goal | subject reads a prepared text | subject speek without support (free speak) |\n",
    "| fluency | good and controlled | hesitations |\n",
    "| pros | easy to compare, repetable | phonetic particularities, diverse | \n",
    "| cons |  reading disorders | emotions inductions, exotic |\n",
    "| mean duration | 50.2 s | 229.8 s |\n",
    "| standard deviation | 10.2 s | 86.2 s|\n",
    "| Min duration| 32.8 s | 70.6 s |\n",
    "| Max duration| 84.1 s | 579.3 s |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
